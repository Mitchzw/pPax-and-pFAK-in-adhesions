{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6885b8a",
   "metadata": {},
   "source": [
    "# Acquiring and processing NN data from NanoJ Core\n",
    "\n",
    "1) Code for ImageJ/Fiji macro that takes images, splits them, measures NN values for separate channels, and saves them in a file. \n",
    "\n",
    "2) different functions in python that are needed to process files obtained in step (1)\n",
    "\n",
    "    - remove entries with a zero for x/y; seem to be NanoJ NN artifacts\n",
    "    \n",
    "    - create new files with entries combined for one condition, also listing cell identifier and replicate for subsequent statistical analysis\n",
    "    \n",
    "    - create lists that contain either distances per cell or distances per replicate\n",
    "    \n",
    "    - create histogram from lists\n",
    "    \n",
    "    - calculate average distance per cell per channel\n",
    "    \n",
    "    - calculate FWHM per cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7f34c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ImageJ plugin to get NN values with NanoJ and save them in separate file\n",
    "\n",
    "Code expects an image with three channel, the first being a labeling used for creating a focal adhesion mask (anti paxillin 633), second one being transfected, RFP labeled construct, third one being anything (anti pFAK, pPax 488 for example).\n",
    "\n",
    "First channel is used to create a rather \"tight\" fitting mask for focal adhesions; second channel (transfected protein) applies another, very broad mask in order to exclude untransfected cells in the field of view.\n",
    "\n",
    "Other order of color channels or labeled proteins will require to adapt numbering. Check how ImageJ names respective channels when you \"split color\" (C1-..., C2-..., etc).\n",
    "\n",
    "explanation of variables:\n",
    "\n",
    "dir1: where to save resulting file; either use \"getDirectory\" to have the possibility to browse folders or give a string with file path; comment out what you don't need\n",
    "\n",
    "NN NanoJ Core needs pixel size and a tolerance level as parameter\n",
    "\n",
    "--> getPixelSize and px do exactly that\n",
    "\n",
    "--> tol is variable for tolerance level in NN analysis; 100 for example for Airyscan, 1000 for SIM\n",
    "\n",
    "tol values is also saved in file name of end results to make sure that this information is not lost\n",
    "\n",
    "### macro code starts here; copy paste this to use it in ImageJ/Fiji\n",
    "// Script to batch and save tables from NanoJ core plugin - fixed cells\\\n",
    "// C.Henry and M.Bachmann - V3 - 2021-11-25\\\n",
    " \n",
    "// dir1 = getDirectory(\"Choose Directory To Save Files\"); //un-comment if you want to choose directory every time\n",
    "dir1 = \"/Volumes/LaCie/_iFAK iSrc 3T3/20211122_3T3_Test_iFAK_iSrc/\" //comment out if you want to select directory every time or change path to the correct one\n",
    "NbSlice = nSlices();\n",
    "ImageName = getTitle();\n",
    "ScriptTitle = \"Nearest-Neighbour Table\";\n",
    "getPixelSize(unit, pw, ph, pd);\n",
    "px = pw*1000 //get pixel size in nm for NN plugin later to make sure it uses the right pixel size\n",
    "tol = 100 // tolerance level for NN plugin\n",
    "\n",
    "// split image and create mask based on channel = 1, usually Pax 633\n",
    "\tselectWindow(ImageName);\n",
    "\trun(\"Split Channels\");\n",
    "\tselectWindow(\"C1-\"+ImageName);\n",
    "\trun(\"Duplicate...\", \" \");\n",
    "\trename(\"mask\");\n",
    "\trun(\"Subtract Background...\", \"rolling=1 sliding\"); //settings should work for Airy Scan images\n",
    "\tsetAutoThreshold(\"Otsu dark\");\n",
    "\trun(\"Threshold...\");\n",
    "\trun(\"Create Selection\");\n",
    "\trun(\"Enlarge...\", \"enlarge=-0.1\"); \n",
    "\trun(\"Enlarge...\", \"enlarge=0.1\"); // reduce and enlarge to remove small features\n",
    "\t// run(\"Clear Outside\"); //replaced with invert-set = 0\n",
    "\trun(\"Make Inverse\"); // delete everything outside of selection\n",
    "\trun(\"Set...\", \"value=0\");\n",
    "\trun(\"Select None\");\n",
    "\n",
    "// for transfected cells: Make a mask with transfected signal to remove all un-transfected cells, assuming channel 2 is transfected signal\n",
    "// but using it for antibody-staining only images shouldn't be a problem in general; mostly depends on signal distribution in channel 2\n",
    "\tselectWindow(\"C2-\"+ImageName);\n",
    "\tsetAutoThreshold(\"Otsu dark\");\n",
    "\trun(\"Threshold...\");\n",
    "\trun(\"Create Selection\");\n",
    "\trun(\"Enlarge...\", \"enlarge=0.5\");\n",
    "\tselectWindow(\"mask\"); \n",
    "\trun(\"Restore Selection\"); //apply mask for transfected signal to mask of paxillin and remove adhesions outside of transfected cell\n",
    "\trun(\"Make Inverse\");\n",
    "\trun(\"Set...\", \"value=0\");\n",
    "\trun(\"Select None\");\n",
    "\tsetAutoThreshold(\"Otsu dark\");\n",
    "\trun(\"Threshold...\");\n",
    "\trun(\"Create Selection\"); // final selection of adhesions only within transfected cell\n",
    "\n",
    "// loop that goes through all channels, applies mask to limit to adhesions within transfected cell and measures NN\n",
    "for (i=1; i<NbSlice+1; i++) {\n",
    "\tselectWindow(\"mask\");\n",
    "\tselectWindow(\"C\"+i+\"-\"+ImageName);\n",
    "\trun(\"Restore Selection\");\n",
    "\trun(\"Make Inverse\");\n",
    "\trun(\"Set...\", \"value=0\");\n",
    "\trun(\"Select None\");\n",
    "\trun(\"Nearest-Neighbours Analysis\", \"tolerance=\" + tol +\" number=250 pixel=\"+px);\n",
    "    if (i == 1) {\n",
    "               ColName = newArray(4);\n",
    "               ColName[0] = \"x-position\";\n",
    "               ColName[1] = \"y-position\";\n",
    "               ColName[2] = \"closest neighbour distance (pixels)\";\n",
    "               ColName[3] = \"closest neighbour distance (nm)\";\n",
    "               DataArray1 = newArray();\n",
    "               DataArray2 = newArray();\n",
    "               DataArray3 = newArray();\n",
    "               DataArray4 = newArray();\n",
    "               DataArrayIdx = newArray();\n",
    "        }\n",
    "        ColTemp = Table.getColumn(ColName[0], ScriptTitle);\n",
    "        DataArray1 = Array.concat(DataArray1, ColTemp);\n",
    "        ColTemp = Table.getColumn(ColName[1], ScriptTitle);\n",
    "        DataArray2 = Array.concat(DataArray2, ColTemp);\n",
    "        ColTemp = Table.getColumn(ColName[2], ScriptTitle);\n",
    "        DataArray3 = Array.concat(DataArray3, ColTemp);\n",
    "        ColTemp = Table.getColumn(ColName[3], ScriptTitle);\n",
    "        DataArray4 = Array.concat(DataArray4, ColTemp);\n",
    "\t\t\n",
    "        NbValues = ColTemp.length;\n",
    "        for (j=0; j<NbValues; j++) {\n",
    "\t\t\tDataArrayIdx = Array.concat(DataArrayIdx,i);\n",
    "\t\t}\n",
    "\t\tclose(\"Nearest Neighbours Voronoi (nm)\");\n",
    "\t\tclose(\"Histogram of nearest-neighbour distances\");\n",
    "}\n",
    "\n",
    "Table.create(\"FinalTable; tolerance: \" + tol);\n",
    "Table.setColumn(ColName[0], DataArray1, \"FinalTable; tolerance: \" + tol);\n",
    "Table.setColumn(ColName[1], DataArray2, \"FinalTable; tolerance: \" + tol);\n",
    "Table.setColumn(ColName[2], DataArray3, \"FinalTable; tolerance: \" + tol);\n",
    "Table.setColumn(ColName[3], DataArray4, \"FinalTable; tolerance: \" + tol);\n",
    "Table.setColumn(\"Slice\", DataArrayIdx, \"FinalTable; tolerance: \" + tol);\n",
    "Table.update(\"FinalTable; tolerance: \" + tol);\n",
    "Table.save(dir1 + \"_\" + ImageName + \"_Table-\" + tol + \".txt\", \"FinalTable; tolerance: \" + tol);\n",
    "\n",
    "print(\"Job done with tolerance level \" + tol + \" and pixel size \" + px);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca6af35",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## collection of python functions to make data from NN files obtained with macro code above accessible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69abb2a4",
   "metadata": {},
   "source": [
    "### general strategy: \n",
    "\n",
    "ImageJ macro gave plenty of single files with NN data for several cells from several independent experiments. \n",
    "\n",
    "Code has to go through folder, read all files, and save correct information into separate files for each color channel. New files should contain distance values (>= 100 nm to <= 1000 nm), cell identifier, and identifier for independent experiment.\n",
    "\n",
    "I name files always the same way \"yyyymmdd_cellLine_condition_...\". \n",
    "--> independent experiments will be identified based on the date (yyyymmdd format) in the file name; file name will be split based on \"_\". Other naming system will require to adapt this part of the code or the file naming system.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfbe3edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ident_replicate(file):\n",
    "    \"\"\"\n",
    "    file name will be split based on '_' \n",
    "    \n",
    "    --> Make sure that filename has date \n",
    "    separated by underscore and has date in format yyyymmdd. Date is recognized \n",
    "    as being an integer > 20000000 meaning that having another integer in the \n",
    "    file name that is not the date of experiment will create problems.\n",
    "    \n",
    "    Input is name of a file, return value is date of experiment as integer \n",
    "    \"\"\"\n",
    "    \n",
    "    file_name = file.split('_') #split file name in parts identified by \"_\" between them\n",
    "    \n",
    "    exp_date = 0 #variable to hold date of experiment\n",
    "    \n",
    "    # this loop goes through the split file name and looks with \"try int()\" for possible \n",
    "    # integers; if an integer is bigger than 2000 00 00 it is considered to be a date \n",
    "    # and is used as output of the function\n",
    "    for index, i in enumerate(file_name):\n",
    "        try:\n",
    "            date = int(file_name[index])\n",
    "            if date > 20000000:\n",
    "                exp_date = date\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return(exp_date)\n",
    "\n",
    "\n",
    "\n",
    "def NN_summary(file_path, output_path, condition, counter=1): \n",
    "    \"\"\"\n",
    "    Creating new summary files for each color channel based on all files for a given \n",
    "    experimental condition. Input files are considered to be .txt files, \n",
    "    output will be .csv and can be saved in separate folder\n",
    "    \n",
    "    Output files are created in append mode; be aware when calling several times. \n",
    "    \n",
    "    \n",
    "    Input:\n",
    "    file_path = path of data files\n",
    "    output_path = folder for output data\n",
    "    condition = used to name output files to identify experimental condition later on\n",
    "    counter = counter for the number of files analysed, first time will be used to write \n",
    "              a header into the output files; default of '1' will lead to a header. Counter\n",
    "              is also used as an identifier of separate cells. This information will \n",
    "              be lost if counter is not increased when function is called in a loop.\n",
    "    \"\"\"\n",
    "    \n",
    "    # naming of output files for three different channels\n",
    "    output01 = output + condition + '_slice01.csv'\n",
    "    output02 = output + condition + '_slice02.csv'\n",
    "    output03 = output + condition + '_slice03.csv'\n",
    "    \n",
    "    # opening data files for reading and output files for writing in append mode\n",
    "    # to hold information from all single files \n",
    "    with open(file_path, 'r') as f_in, open(output01, 'a') as f_out01, open(output02, 'a') as f_out02, open(output03, 'a') as f_out03:\n",
    "        \n",
    "        # remove header of data files\n",
    "        line = f_in.readline() \n",
    "        \n",
    "        # get file name from file path\n",
    "        file = (file_path.split('/'))[-1]\n",
    "        \n",
    "        # call function to get date as int from file name to identify \n",
    "        # independent experiments later on\n",
    "        date_experiment = ident_replicate(file)\n",
    "        \n",
    "        # writing headers for output files\n",
    "        # put counter either to != 1 or increase with a loop if you don't want the \n",
    "        # header several times in your file; but be aware that counter is also used\n",
    "        # as cell identifier\n",
    "        if counter == 1:\n",
    "            print ('distance', 'date_experiment', 'cell', file = f_out01, sep = ',')\n",
    "            print ('distance', 'date_experiment', 'cell', file = f_out02, sep = ',')\n",
    "            print ('distance', 'date_experiment', 'cell', file = f_out03, sep = ',')\n",
    "            \n",
    "        # looping through lines of data file \n",
    "        for line in f_in:\n",
    "            data = line.strip().split('\\t')\n",
    "            x_pos = float(data[0])\n",
    "            distance = float(data[3])\n",
    "            slice_nr = float(data[4])\n",
    "            \n",
    "            # identifying suitable data, x = 0 is artifical entry from NanoJ Core, \n",
    "            # limit of 1000 nm is set by me assuming that longer distances are \n",
    "            # unlikely within the same adhesion\n",
    "            # data will be printed into respective output files based on slice \n",
    "            # entry in data file\n",
    "            if (x_pos >= 100) and (distance <= 1000): \n",
    "                if slice_nr == 1:\n",
    "                    print (distance, date_experiment, counter, file = f_out01, sep = ',')\n",
    "                    \n",
    "                elif slice_nr == 2:\n",
    "                    print (distance, date_experiment, counter, file = f_out02, sep = ',')\n",
    "                    \n",
    "                elif slice_nr == 3:\n",
    "                    print (distance, date_experiment, counter, file = f_out03, sep = ',')\n",
    "\n",
    "                    \n",
    "\n",
    "def create_arrays_average(file_path):\n",
    "    \"\"\"\n",
    "    Creates and returns a dictionarry with date of experiments as keys and all distances \n",
    "    with same key as values. \n",
    "    \n",
    "    Input:\n",
    "    path to file that contains all distance values for one labeling, supposed to be \n",
    "    a .csv file (i.e. file created by function NN_summary) with distance at first position\n",
    "    in line and replicate at second position in line\n",
    "    \n",
    "    Such a dictionnary can later be used to get data sorted per independent experiment. \n",
    "    But connection to single cell data is lost.\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_path,'r') as f_01:\n",
    "        # remove header\n",
    "        f_01.readline()\n",
    "        \n",
    "        #dic_replicates = 0\n",
    "        dic_replicates = {} #initialize dictionary with keys = replicates and values = distances\n",
    "        dic_cells = {} #initialize dictionary with keys = replicates and values = cell ID\n",
    "        \n",
    "        for line in f_01:\n",
    "            data = line.strip().split(',')\n",
    "            distance = float(data[0])\n",
    "            replicate = float(data[1])\n",
    "            \n",
    "            \n",
    "            if not replicate in dic_replicates: #key with respective name is created if not already existent\n",
    "                dic_replicates[replicate] = []        \n",
    "        \n",
    "            dic_replicates[replicate].append(distance) #add distance values to resp key\n",
    "        \n",
    "    return(dic_replicates) # returns dic with replicates as keys and distances as values\n",
    "\n",
    "\n",
    "\n",
    "def create_arrays_average_02(file_path):\n",
    "    \"\"\"\n",
    "    Creates and returns a dictionarry with cell identifier as keys and all distances \n",
    "    with same key as values. \n",
    "    \n",
    "    Input:\n",
    "    path to file that contains all distance values for one labeling, supposed to be \n",
    "    a .csv file (i.e. file created by function NN_summary) with distance at first position\n",
    "    in line and cell identifier at third position in line. replicate is currently not \n",
    "    used (replicate is second position in line)\n",
    "    \n",
    "    Such a dictionnary can later be used to use all the distance data connected to \n",
    "    individuell cells. \n",
    "    \"\"\"\n",
    "    \n",
    "    with open(file_path,'r') as f_01:\n",
    "        # remove header\n",
    "        f_01.readline()\n",
    "        \n",
    "        dic_cells = {} #dic with cells as keys and distances as values\n",
    "        \n",
    "        for line in f_01:\n",
    "            data = line.strip().split(',')\n",
    "            distance = float(data[0])\n",
    "            cell = float(data[2])\n",
    "            \n",
    "            if not cell in dic_cells: #key with respective name is created if not \n",
    "                                        #already existent\n",
    "                dic_cells[cell] = []        \n",
    "        \n",
    "            dic_cells[cell].append(distance) #add distance values to resp key\n",
    "        \n",
    "    return(dic_cells) # returns dic with cells as keys and distances as values\n",
    "\n",
    "\n",
    "\n",
    "def make_histo(distance_values): #give a list with distance values as input, (values from dic with keys as replic)\n",
    "    \"\"\"\n",
    "    Takes dictionary created with function 'create_arrays_average' as input and make numpy \n",
    "    array and subsequently calculate histogram distribution for each replicate.\n",
    "    Histograms are also normalized to max value.\n",
    "    \n",
    "    Histogram bins are set within function.\n",
    "    \n",
    "    Returns normalized histogram data and list with bins\n",
    "    \"\"\"\n",
    "    \n",
    "    bins = [0,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000]\n",
    "    array = np.array(distance_values) \n",
    "    histo, bin_edges = np.histogram(array, bins=bins, density=False)\n",
    "    histo_norm = [float(i)/max(histo) for i in histo]\n",
    "    del bins[0]\n",
    "    return histo_norm, bins\n",
    "\n",
    "\n",
    "\n",
    "def create_arrays(file_path):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    dic_cells = {}  # \n",
    "    dic_replicate = {}\n",
    "    with open(file_path,'r') as f_01:\n",
    "        # remove header\n",
    "        f_01.readline()\n",
    "        \n",
    "        for line in f_01:\n",
    "            data = line.strip().split(',')\n",
    "            distance = float(data[0])\n",
    "            replicate = float(data[1])\n",
    "            cell = float(data[-1])\n",
    "            \n",
    "            #key with respective name is created if not already existent\n",
    "            if not replicate in dic_replicate: \n",
    "                dic_replicate[replicate] = []        \n",
    "            \n",
    "            #add cell nr to resp key\n",
    "            dic_replicate[replicate].append(cell) \n",
    "            \n",
    "            #key with respective name is created if not already existent\n",
    "            if not cell in dic_cells: \n",
    "                dic_cells[cell] = []        \n",
    "        \n",
    "            dic_cells[cell].append(distance) #add distance values to resp key\n",
    "        \n",
    "    return(dic_cells, dic_replicate) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59b9b26",
   "metadata": {},
   "source": [
    "\n",
    "## Calling functions for creating output files with summarized distance values and histogram data\n",
    "\n",
    "The idea is that you have one folder per condition that contains all NN files, in .txt format, from several experiments, obtained with ImageJ Macro from above, for this given condition. Filename needs to contain date in yyyymmdd format separated with \"_\".\n",
    "Folder should also contain an empty output folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6835012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# information about path of input files and folder for output files, \n",
    "# as well as \"condition\" = name used for output files\n",
    "\n",
    "path = \"/Users/michaelbachmann/Python/pPax paper/Figure05/test\"\n",
    "output = path + \"/output/\"\n",
    "\n",
    "# condition and name for the output files\n",
    "condition = 'FAKwt'\n",
    "\n",
    "# change these if conditions are not like this from your ImageJ output files\n",
    "channel01 = 'Pax'\n",
    "channel02 = condition\n",
    "channel03 = 'pFAK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ceaab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create summary files that contains distance data from all separate files\n",
    "# files will be saved in output folder and be named according to variable 'condition'\n",
    "# and with slice01, slice02, slice03 for channels according to ImageJ Macro\n",
    "# in case of Bachmann et al, pPax paper: 1 being Pax, 2 being FAK construct, 3 being pFAK\n",
    "\n",
    "# Import Module\n",
    "import os\n",
    "\n",
    "# Change the directory to the one given in the first code cell with variable \"path\"\n",
    "os.chdir(path)  \n",
    "\n",
    "# index for file numbers, used to identify data from individual cells and to write \n",
    "# header at the start of output files\n",
    "index = 1\n",
    "                    \n",
    "# iterate through all files in path defined by variable \"path\"; \n",
    "\n",
    "for file in os.listdir():\n",
    "    \n",
    "    # Check whether file is in text format or not\n",
    "    if file.endswith(\".txt\"):\n",
    "        file_path = f\"{path}/{file}\"\n",
    "        \n",
    "        #process data, i.e. remove 0, split according to color\n",
    "        NN_summary(file_path, output, condition, index)\n",
    "        index += 1 #add one to counter of analyzed cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "469c1b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create file that contains histogram data from distances pooled per \n",
    "# independent experiment\n",
    "# file will be named after variable 'condition' and with '_histo_output.txt'\n",
    "# output folder should contain 3 files ending with 'slice01', ..., 'slice03' and they\n",
    "# will be named assuming that 01 is Pax, 03 is pFAK, and that 02 is variable 'condition'\n",
    "\n",
    "# Import Module\n",
    "import os\n",
    "\n",
    "# Change the directory to the directory of the output files\n",
    "os.chdir(output)\n",
    "\n",
    "with open(condition + \"_histo_output.txt\", 'w') as f_out:\n",
    "    print ('index', 'condition', 'bin', 'bin value', file = f_out, sep = '\\t')\n",
    "\n",
    "    # iterate through all file\n",
    "    index_counter = 1\n",
    "    for file in os.listdir():\n",
    "        \n",
    "        # Check whether file is in csv format or not\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = f\"{output}{file}\"\n",
    "            \n",
    "            #call function to make dic. for ind. exp. and dis. values\n",
    "            dic_replicates = create_arrays_average(file_path) \n",
    "            \n",
    "            #go through dictionary key (=ind.exp.) by key and create histogram for all\n",
    "            #distances belonging to this replicate\n",
    "            for key in dic_replicates:\n",
    "                \n",
    "                bin_value, distance = make_histo(dic_replicates[key]) #calc. histogram\n",
    "                \n",
    "                # file[-5] is the slice number in the file name and \n",
    "                # therefore indicates condition\n",
    "                if int(file[-5]) == 1:\n",
    "                    channel = channel01\n",
    "                elif int(file[-5]) == 2:\n",
    "                    channel = channel02\n",
    "                elif int(file[-5]) == 3:\n",
    "                    channel = channel03\n",
    "                    \n",
    "                # go through lists of bin values and print them together with number of\n",
    "                # respective bin\n",
    "                for i, dist in enumerate(bin_value): \n",
    "                    print (index_counter,\n",
    "                           channel,\n",
    "                           distance[i],\n",
    "                           bin_value[i],\n",
    "                           file = f_out, \n",
    "                           sep = '\\t')\n",
    "                \n",
    "                #increase counter that will indicate separate experiments\n",
    "                index_counter += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8549cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates output files that contain average distances per cell named \n",
    "# 'average-distance.txt'. \n",
    "# column replicate is empty and replicates have to be calculated with second part, creating\n",
    "# file 'cell-rep.txt'. Not very elegant but I didn't find another way. \n",
    "\n",
    "# Import Module\n",
    "import os\n",
    "\n",
    "# Change the directory to the directory of the output files\n",
    "os.chdir(output)\n",
    "\n",
    "\n",
    "# this part creates file with average values\n",
    "with open(condition + \"_average-distance.txt\", 'w') as f_out:\n",
    "    print ('index', 'condition', 'average distance', 'replicate', file = f_out, sep = '\\t')\n",
    "\n",
    "    \n",
    "    # iterate through all files\n",
    "    for file in os.listdir():\n",
    "\n",
    "        average_dis = [] #creaty empty list for average distances\n",
    "        \n",
    "        # Check whether file is in csv format or not\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = f\"{output}{file}\"\n",
    "            \n",
    "            # file[-5] is the slice number in the file bame and therefore indicates condition\n",
    "            if int(file[-5]) == 1:\n",
    "                channel = channel01\n",
    "            elif int(file[-5]) == 2:\n",
    "                channel = channel02\n",
    "            elif int(file[-5]) == 3:\n",
    "                channel = channel03\n",
    "            \n",
    "            # calls function ...average_02 that creates a dic. per cell and not per\n",
    "            # ind. experiment as the case for ...average\n",
    "            dic_cells = create_arrays_average_02(file_path)\n",
    "            \n",
    "            for cell in dic_cells: \n",
    "                print (cell, channel, sum(dic_cells[cell]) / len(dic_cells[cell]), file=f_out, sep='\\t')\n",
    " \n",
    "# this part creates file with list of exp. dates; can be copy pasted later on to\n",
    "# file _average-distances to connect average distances with replicates. \n",
    "# the way it work is that one of the output files (...slice01.csv) is taken and the order\n",
    "# of exp dates is read and written into new file\n",
    "with open(condition+'_slice01.csv', 'r') as f_in, open(condition+\"_cell-rep.txt\", 'w') as f_out:\n",
    "    f_in.readline()\n",
    "    \n",
    "    # dic pairing cell identifier with replicate\n",
    "    dic_pairing = {} \n",
    "\n",
    "    for line in f_in:\n",
    "\n",
    "        data = line.strip().split(',')\n",
    "        replicate = float(data[1])\n",
    "        cell = float(data[2])\n",
    "\n",
    "        if not cell in dic_pairing:\n",
    "            dic_pairing[cell] = [] #this cell identifier is made a key\n",
    "            \n",
    "            #if this key has no entry yet, it gets exp date as entry, \n",
    "            #connecting cell identifier with exp date and thereby replicate\n",
    "            if not replicate in dic_pairing[cell]: \n",
    "                                                \n",
    "                dic_pairing[cell].append(replicate)\n",
    "\n",
    "    for cell in dic_pairing:\n",
    "        print (dic_pairing[cell], file=f_out, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a315fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates new file containing FWHM values named 'histo_output_FWHM.txt'\n",
    "# input comes again from csv files slice01, ..., slice03\n",
    "# output file contains experimental date to identify replicates, condition analyzed, and\n",
    "# number of bins with value >= 0.5 multiplied with 50 as FWHM(nm) value\n",
    "\n",
    "# Import Module\n",
    "import os\n",
    "\n",
    "# Change the directory to the directory of the output files\n",
    "os.chdir(output)\n",
    "\n",
    "with open(condition + \"_histo_output_FWHM.txt\", 'w') as f_out:\n",
    "\n",
    "    print ('date', 'condition', 'FWHM(nm)', file = f_out, sep = '\\t')\n",
    "    \n",
    "    for file in os.listdir():\n",
    "        \n",
    "        # iterate through all file\n",
    "        index_counter = 1\n",
    "        \n",
    "        # Check whether file is in csv format or not\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = f\"{output}{file}\"\n",
    "            \n",
    "            # create two dic, one with cells as keys, one with replicates as key\n",
    "            dic_cells, dic_replicate = create_arrays(file_path)\n",
    "\n",
    "            #go through all cells/keys from dic_cells to calculate FWHM per cell\n",
    "            for cell in dic_cells:\n",
    "                \n",
    "                #connect cell with a replicate by checking if cell is a value in \n",
    "                #dic_replicate for given exp date\n",
    "                for date_experiment in dic_replicate:\n",
    "                    if cell in dic_replicate[date_experiment]:\n",
    "                        cell_date = date_experiment\n",
    "                \n",
    "                #create counter for bin >= 0.5\n",
    "                counter_FWHM = 0\n",
    "                \n",
    "                #create histogramm for individual cell data\n",
    "                bin_value, distance = make_histo(dic_cells[cell])\n",
    "                \n",
    "                # file[-5] is the slice number in the file bame and \n",
    "                # therefore indicates condition\n",
    "                if int(file[-5]) == 1:\n",
    "                    channel = channel01\n",
    "                elif int(file[-5]) == 2:\n",
    "                    channel = channel02\n",
    "                elif int(file[-5]) == 3:\n",
    "                    channel = channel03\n",
    "                    \n",
    "                #go through bin values from histogram, check if >= 0.5, add 1 to counter\n",
    "                #variable and print all information when last value per cell is reached\n",
    "                #number of bins >= 0.5 is multiplied with 50 according to bin width\n",
    "                for i, dist in enumerate(bin_value):\n",
    "                    if bin_value[i] >= 0.5:\n",
    "                        counter_FWHM += 1\n",
    "                    if distance[i] == 1000:\n",
    "                        print (\n",
    "                            cell_date, channel, counter_FWHM*50,  \n",
    "                            file = f_out, sep ='\\t'\n",
    "                                )\n",
    "                        \n",
    "                \n",
    "                index_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadf2a55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
